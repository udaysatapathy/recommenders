{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RecommenderData import RecommenderData\n",
    "from RecommenderComparer import RecommenderComparer\n",
    "from surprise import SVD, SVDpp\n",
    "from surprise import NormalPredictor\n",
    "import numpy as np\n",
    "import random\n",
    "from tabulate import tabulate\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsPath = 'ratings.csv'\n",
    "moviesPath = 'movies.csv'\n",
    "Test_userIDs = [\"85\", \"91\"]\n",
    "doTopN = True\n",
    "\n",
    "# seed for reproducibility\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "# for expanded display in pandas\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the algorithms before comparison\n",
    "SVD_Algorithm = SVD(random_state=10)\n",
    "# SVDpp_Algorithm = SVDpp(random_state=10)\n",
    "Normal_Predictor = NormalPredictor()\n",
    "\n",
    "# creating the comparison set\n",
    "algo_comparison_set = [(SVD_Algorithm, \"SVD\"), (Normal_Predictor, \"Normal\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data\n",
    "recommenderData = RecommenderData(ratingsPath, moviesPath, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set comparer\n",
    "recommenderComparer = RecommenderComparer(recommenderData, algo_comparison_set)\n",
    "# compare\n",
    "comparison = recommenderComparer.Compare(doTopN, verbose=True, sample_topN_for_userIDs=Test_userIDs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # tabulating the comparison\n",
    "header = [\"Algorithm\"]\n",
    "rows = []\n",
    "is_header_done = False\n",
    "\n",
    "# for algo, all_metrics in comparison.items():\n",
    "#     row = [algo]\n",
    "#     for metric_type, metric_value in all_metrics.items():\n",
    "#         row.extend([metric_value])\n",
    "#         # create header only once\n",
    "#         if is_header_done == False:\n",
    "#             header.extend([metric_type])\n",
    "#     is_header_done = True\n",
    "#     rows.extend([row])\n",
    "\n",
    "metrics = {}\n",
    "for algo in comparison.keys():\n",
    "    row = [algo]\n",
    "    metrics = comparison[algo][\"metrics\"]\n",
    "    for metric_type, metric_value in metrics.items():\n",
    "        row.extend([metric_value])\n",
    "        # create header only once\n",
    "        if is_header_done == False:\n",
    "            header.extend([metric_type])\n",
    "    is_header_done = True\n",
    "    rows.extend([row])\n",
    "\n",
    "print(\"\\nComparison results:\\n\")\n",
    "print(tabulate(rows, headers=header))\n",
    "print(\"\\nLegend:\\n\")\n",
    "print(\"RMSE:      Root Mean Squared Error. Lower values mean better accuracy.\")\n",
    "print(\"MAE:       Mean Absolute Error. Lower values mean better accuracy.\")\n",
    "if (doTopN):\n",
    "    print(\"HR:        Hit Rate; how often we are able to recommend a left-out rating. Higher is better.\")\n",
    "    print(\"cHR:       Cumulative Hit Rate; hit rate, confined to ratings above a certain threshold. Higher is better.\")\n",
    "    print(\"ARHR:      Average Reciprocal Hit Rank - Hit rate that takes the ranking into account. Higher is better.\" )\n",
    "    print(\"Coverage:  Ratio of users for whom recommendations above a certain threshold exist. Higher is better.\")\n",
    "    print(\"Diversity: 1-S, where S is the average similarity score between every possible pair of recommendations\")\n",
    "    print(\"           for a given user. Higher means more diverse.\")\n",
    "    print(\"Novelty:   Average popularity rank of recommended items. Higher means more novel.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
